{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e002d8-13ac-441f-8fc8-0c2e8e69a4f5",
   "metadata": {},
   "source": [
    "## ZOIDBERG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ec3d285-33bd-4a76-ab5b-d0ee5c0f290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088e960-70d8-4ffd-a674-3bbdf21d94e8",
   "metadata": {},
   "source": [
    "## Models used\n",
    "- KNN (K-Nearest Neighbors)\n",
    "- SVM (Support Vector Machine)\n",
    "- MLP_classifier (Multi-Layer Perceptron classifier)\n",
    "- Naive Bayes\n",
    "- Extremely Randomized Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8c43b-ab60-4ded-b2f3-74a708c36d13",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7015173-a102-4b5a-b036-f03e2140a0c3",
   "metadata": {},
   "source": [
    "load_data(): This function loads image data from a directory and converts it to grayscale. It returns four lists: train_images, train_labels, test_images, and test_labels. The train_images and train_labels lists contain the training data, and the test_images and test_labels lists contain the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0a23cd16-dd6e-4589-9c81-66827dd6b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Définir le chemin du dossier contenant les images d'entraînement et de test\n",
    "    train_dir = \"/jup/Epitech/Data/chest_Xray/train/\"\n",
    "    test_dir = \"/jup/Epitech/Data/chest_Xray/test/\"\n",
    "\n",
    "    # Définir le nombre de voisins à utiliser pour la classification K-NN\n",
    "    # n_neighbors = 5\n",
    "\n",
    "    # Charger les images d'entraînement et de test, et leurs étiquettes\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for foldername in tqdm([\"NORMAL\", \"PNEUMONIA\"]): # os.listdir(train_dir)\n",
    "        label = 0 if foldername == \"NORMAL\" else 1\n",
    "        folderpath = os.path.join(train_dir, foldername)\n",
    "        for filename in os.listdir(folderpath):\n",
    "            if filename.endswith(\".jpeg\"):\n",
    "                imgpath = os.path.join(folderpath, filename)\n",
    "                img = cv2.imread(imgpath)\n",
    "                if img is None:\n",
    "                    print('Wrong path:', imgpath)\n",
    "                else:\n",
    "                    img = cv2.resize(img, (64, 64))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    train_images.append(img.flatten())\n",
    "                    train_labels.append(label)\n",
    "\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    for foldername in tqdm([\"NORMAL\", \"PNEUMONIA\"]): # os.listdir(test_dir)\n",
    "        label = 0 if foldername == \"NORMAL\" else 1\n",
    "        folderpath = os.path.join(test_dir, foldername)\n",
    "        for filename in os.listdir(folderpath):\n",
    "            if filename.endswith(\".jpeg\"):\n",
    "                imgpath = os.path.join(folderpath, filename)\n",
    "                img = cv2.imread(imgpath)\n",
    "                if img is None:\n",
    "                    print('Wrong path:', imgpath)\n",
    "                else:\n",
    "                    img = cv2.resize(img, (64, 64))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    test_images.append(img.flatten())\n",
    "                    test_labels.append(label)\n",
    "                    \n",
    "    print(\"Finished in\", round((time.time() - start_time), 1), \"s\")\n",
    "                    \n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87723323-06af-48fb-9819-694177d67b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:15<00:00, 37.88s/it]\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 84.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, test_images, test_labels = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de71f29-4518-442b-9299-31998bb0de4b",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab0d55-2f66-47f8-b154-4aa24d26dc52",
   "metadata": {},
   "source": [
    "**The KNN (k-nearest neighbors) model is a supervised learning algorithm used for classification and regression. The basic idea is to find the k closest training samples (based on a distance measure) to the test sample, and then assign a label (for classification) or a value (for regression) to the test sample based on the majority of the labels or values of the k closest neighbors. The larger k is, the smoother the decision boundary will be, but the higher the variance of the estimate will be.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed5c79-d6f3-453e-8a67-f27851ccb84d",
   "metadata": {},
   "source": [
    "KNN(): This function implements the K-Nearest Neighbors algorithm for classification. It takes as input the training and testing data and the number of neighbors to consider (default value is 5). It trains the model on the training data and makes predictions on the testing data. It then calculates the accuracy of the model and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7f11f29-cbaf-48e0-86ef-8afa9ebb0409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(train_images, train_labels, test_images, test_labels, n_neighbors = 5):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Créer un objet KNeighborsClassifier et entraîner le modèle sur les données d'entraînement\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(train_images, train_labels)\n",
    "\n",
    "    # Prédire les classes des images de test\n",
    "    test_preds = knn.predict(test_images)\n",
    "\n",
    "    # Calculer l'exactitude du modèle sur les données de test\n",
    "    accuracy = np.mean(test_preds == test_labels)\n",
    "    print(\"Exactitude du modèle : {:.2f} %\".format(accuracy*100))\n",
    "    print(\"Finished in\", round((time.time() - start_time), 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4af6ebd7-adb8-42ef-ac0e-535c435dab59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitude du modèle : 74.20 %\n",
      "Finished in 0.8 s\n"
     ]
    }
   ],
   "source": [
    "KNN(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7206e1-0b1a-4105-9e64-3edf20291e6f",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d512ec-c809-4545-9c69-33a7d7cad59c",
   "metadata": {},
   "source": [
    "**The SVM (Support Vector Machine) is a supervised learning algorithm used for classification and regression. It consists in finding the best possible separation between classes by looking for a hyperplane that maximizes the margin between the data of the different classes.**\n",
    "\n",
    "**The separation hyperplane is constructed using a subset of the training data called support vectors. These support vectors are the data closest to the decision frontier.**\n",
    "\n",
    "**The SVM model can also use a kernel function to transform the data into a higher dimensional space, where linear separation is easier to achieve. This allows capturing more complex relationships between the data.**\n",
    "\n",
    "**The SVM model is known for its ability to handle data with a large number of variables, as well as its ability to generalize to new data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1148d817-1fb0-4dc5-a671-09e7460c302c",
   "metadata": {},
   "source": [
    "SVC(): This function implements the Support Vector Machine (SVM) algorithm for classification. It takes as input the training and testing data and a boolean value indicating whether to use a linear kernel or not (default value is False, indicating to use the default kernel). It trains the model on the training data and makes predictions on the testing data. It then calculates the accuracy of the model and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9c605cc2-9d36-431a-b3f9-19fc949346f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC(train_images, train_labels, test_images, test_labels, linear: bool = False):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if not linear:\n",
    "        \n",
    "        clf = svm.SVC(verbose=True)\n",
    "        clf.fit(train_images, train_labels)\n",
    "        predicted = clf.predict(test_images)\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        clf = svm.LinearSVC(verbose=True)\n",
    "        clf.fit(train_images, train_labels)\n",
    "        predicted = clf.predict(test_images)\n",
    "    \n",
    "    print(\"Accuracy:\", round(metrics.accuracy_score(test_labels, predicted)*100, 2), \"%\")\n",
    "    print(\"Finished in\", round((time.time() - start_time), 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "32dad193-f7cb-422d-bca7-6a62589edda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Accuracy: 76.12 %\n",
      "Finished in 24.4 s\n"
     ]
    }
   ],
   "source": [
    "SVC(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f98824-9442-45bd-a13d-ace065dc9fb0",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5ea06-601d-42d1-bfab-521e59adab62",
   "metadata": {},
   "source": [
    "**The MLP (Multi-Layer Perceptron) model is a type of artificial neural network used for classification. It is composed of several layers of connected neurons that transform the input into a predicted output. The input data is passed through hidden layers that apply activation functions to generate intermediate outputs. These outputs are then passed to the output layer, where the output class is predicted based on the inputs and connection weights. The model is trained to adjust the connection weights to minimize a cost function that measures the difference between the predicted output and the actual output. The model can be used for multi-class classification and regression problems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42240d24-1417-4f19-a857-7c0a4afad5e0",
   "metadata": {},
   "source": [
    "MLP_classifier(): This function implements a multilayer perceptron (MLP) algorithm for classification. It takes as input the training and testing data. It creates an MLP classifier with a hidden layer size of (784, 3) and trains the model on the training data. It then makes predictions on the testing data, calculates the accuracy of the model, and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60a51256-f098-4b11-a201-7304e0f2826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_classifier(train_images, train_labels, test_images, test_labels):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    clf = MLPClassifier(verbose=True, solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(784, 3), random_state=1)\n",
    "    clf.fit(train_images, train_labels)\n",
    "    predicted = clf.predict(test_images)\n",
    "    \n",
    "    print(\"Accuracy:\", round(metrics.accuracy_score(test_labels, predicted)*100, 2), \"%\")\n",
    "    print(\"Finished in\", round((time.time() - start_time), 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2e3c5b4-e78e-4be7-a576-d59eb939f489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.18 %\n",
      "Finished in 26.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "MLP_classifier(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9f7c2-a0b3-4966-bd0c-13ba76c71948",
   "metadata": {},
   "source": [
    "## NAIVE Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c72dd-8a03-4d10-9345-19dc60681aa7",
   "metadata": {},
   "source": [
    "**The Naive Bayes model is a supervised learning algorithm that is used for text classification and prediction of the probability of an observation belonging to a certain class. The model calculates the probability of each class for a given observation using Bayes' theorem. It assumes that each feature is independent of the other, hence the term \"naive\". The training data is used to calculate the probabilities of the different characteristics for each class. During prediction, the model calculates the probabilities of each class for the given observation using the previously calculated probabilities and chooses the class with the highest probability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4333661-cc62-4427-a14a-1658eaff04d7",
   "metadata": {},
   "source": [
    "NAIVE_bayes(): This function implements the Naive Bayes algorithm for classification. It takes as input the training and testing data, fits the model to the training data, makes predictions on the testing data, calculates the accuracy of the model, and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2fa83541-0560-4d4b-aa27-b480f6431b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAIVE_bayes(train_images, train_labels, test_images, test_labels):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    # fit the model with the training data\n",
    "    model.fit(train_images, train_labels)\n",
    "\n",
    "    predicted = model.predict(test_images)\n",
    "    \n",
    "    print(\"Accuracy:\", round(metrics.accuracy_score(test_labels, predicted)*100, 2), \"%\")\n",
    "    print(\"Finished in\", round((time.time() - start_time), 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "348a9798-715e-4af1-94b3-bc2f5032bccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.76 %\n",
      "Finished in 0.8 s\n"
     ]
    }
   ],
   "source": [
    "NAIVE_bayes(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfda76-ab05-4218-821d-cc463d687d55",
   "metadata": {},
   "source": [
    "## EXTREMELY Randomized Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491cd22-25e6-42ae-b95e-fb0990465acd",
   "metadata": {},
   "source": [
    "**The Extremely Randomized Trees (ERT) model is an extension of the Random Forest algorithm that uses a set of many decision trees. However, unlike Random Forest, the decision trees in ERT are constructed using random cutoffs for the data features, rather than the optimal cutoffs. In addition, the tree splitting is done using a randomly selected sample subset of features for each node.**\n",
    "\n",
    "**By using randomly chosen cutoffs and features, ERT seeks to increase diversity between decision trees, which can lead to reduced variance and improved model generalization. In addition, the use of the randomly selected feature subset set can help reduce the correlation between trees, which can also improve model performance.**\n",
    "\n",
    "**ERT is particularly useful for high-dimensional and noisy datasets, as well as for datasets with features that have complex and nonlinear interactions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee397c-169c-411f-86f5-b5ac8b92351f",
   "metadata": {},
   "source": [
    "EXTREMELY_randomized_trees(): This function implements the Extremely Randomized Trees algorithm for classification. It takes as input the training and testing data, the number of estimators to use (default value is 100), and the maximum depth of the trees (default value is 10). It trains the model on the training data and makes predictions on the testing data. It then calculates the accuracy of the model and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "603bfbed-30fa-4391-994e-399c07f7ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EXTREMELY_randomized_trees(train_images, train_labels, test_images, test_labels, estimators: int = 100, max_depth: int = 10):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ExtraTrees classifier always tests random splits over fraction of features\n",
    "    # (in contrast to RandomForest, which tests all possible splits over fraction of features)\n",
    "\n",
    "    clf = ExtraTreesClassifier(n_estimators=estimators, max_depth=max_depth, min_samples_split=2, random_state=0)\n",
    "    clf = clf.fit(train_images, train_labels)\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    predicted = clf.predict(test_images)\n",
    "    \n",
    "    print(\"Accuracy:\", round(metrics.accuracy_score(test_labels, predicted)*100, 2), \"%\")\n",
    "    print(\"Finished in\", round((time.time() - start_time), 1), \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7ee2fd5c-9130-4737-814d-562925cff43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.6 %\n",
      "Finished in 8.2 s\n"
     ]
    }
   ],
   "source": [
    "EXTREMELY_randomized_trees(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ecd32c-5015-4bc1-af7d-33c8b922268a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Data ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:12<00:00, 36.07s/it]\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 80.7 s\n",
      "\n",
      "=== KNN Model ===\n",
      "Exactitude du modèle : 74.20 %\n",
      "Finished in 0.5 s\n",
      "\n",
      "=== SVC Model ===\n",
      "[LibSVM]Accuracy: 76.12 %\n",
      "Finished in 24.0 s\n",
      "\n",
      "=== MLP Classifier Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.18 %\n",
      "Finished in 27.9 s\n",
      "\n",
      "=== NAIVE bayes Model ===\n",
      "Accuracy: 72.76 %\n",
      "Finished in 0.6 s\n",
      "\n",
      "=== EXTREMELY randomized trees Model ===\n",
      "Accuracy: 76.6 %\n",
      "Finished in 8.0 s\n"
     ]
    }
   ],
   "source": [
    "from Zoidberg_Object import ZOIDBERG\n",
    "z = ZOIDBERG()\n",
    "z.compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fad6a-4bb1-4219-8109-96b4b53b90d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "198cf63e-7e95-4257-a16b-d312a7d52e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert Zoiberg_Draft.ipynb to html\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from Tool import tool\n",
    "tool.convert2html(\"Zoidberg_Draft.ipynb\", \"Draft_14-03-23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457de3bc-be9f-448e-8585-c8af73051c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
