{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048bdae8-f2d4-45fa-8a5f-225f9799b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fae705-68f0-4d4e-b1ed-16375c3fdc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09417356-bf78-4c08-a0bb-57b9700639bc",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "n_estimators = number of trees in the foreset <br>\n",
    "max_features = max number of features considered for splitting a node <br>\n",
    "max_depth = max number of levels in each decision tree <br>\n",
    "min_samples_split = min number of data points placed in a node before the node is split <br>\n",
    "min_samples_leaf = min number of data points allowed in a leaf node <br>\n",
    "bootstrap = method for sampling data points (with or without replacement) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e21917-a258-4ec0-9814-d95b62201c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af13787-6853-4e04-85be-582e7e373063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:19<00:00, 39.60s/it]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 88.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Zoidberg_Object import ZOIDBERG\n",
    "zb = ZOIDBERG()\n",
    "train_features, train_labels, test_features, test_labels = zb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b9ba4-f54f-4cd7-be55-1875be19b761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d2778a1-84c8-4dca-b76c-ba419684ac74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 30,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c01e1c55-2fd5-4b54-bae8-4d4e0f1f7652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best10\n",
    "# {'n_estimators': 200,\n",
    "#  'min_samples_split': 10,\n",
    "#  'min_samples_leaf': 2,\n",
    "#  'max_features': 'sqrt',\n",
    "#  'max_depth': 50,\n",
    "#  'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "781f7abb-4baf-4474-85ee-71a21128eba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 30,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best100\n",
    "# {'n_estimators': 400,\n",
    "#  'min_samples_split': 5,\n",
    "#  'min_samples_leaf': 1,\n",
    "#  'max_features': 'sqrt',\n",
    "#  'max_depth': 30,\n",
    "#  'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ef47f2-768f-4bbc-8a33-51fbab936cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best10 = {'n_estimators': 200,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 50,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56839dc0-4eaf-4980-b0ef-9d562fbd5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "best100 = {'n_estimators': 400,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 30,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc8aedd-dcdf-4b81-9fd0-706880011b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b5fe23-4229-4fac-b2c8-c1e83eec0ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.2723 degrees.\n",
      "Accuracy = nan%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(train_features, train_labels)\n",
    "base_accuracy = evaluate(base_model, test_features, test_labels)\n",
    "# Model Performance\n",
    "# Average Error: 3.9199 degrees.\n",
    "# Accuracy = 93.36%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae6b75f-5013-41c7-b670-48cc9433baa0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8173fa0a07c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrandom_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Model Performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Average Error: 3.7152 degrees.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Accuracy = 93.73%.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_random' is not defined"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, test_features, test_labels)\n",
    "# Model Performance\n",
    "# Average Error: 3.7152 degrees.\n",
    "# Accuracy = 93.73%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9fe5c-f588-4099-a447-021b293e0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))\n",
    "# Improvement of 0.40%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80efb7a-ea2a-4700-9400-e88170fa2aa5",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f948fa3-0d5f-42c9-baf7-588c09dce882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fde5517c-9cef-4107-b221-af42bc539adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 80,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_features, train_labels)\n",
    "grid_search.best_params_\n",
    "# {'bootstrap': True,\n",
    "#  'max_depth': 80,\n",
    "#  'max_features': 3,\n",
    "#  'min_samples_leaf': 5,\n",
    "#  'min_samples_split': 12,\n",
    "#  'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31c4c93e-f845-4435-9efc-2a1f14045552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.2885 degrees.\n",
      "Accuracy = -inf%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, test_features, test_labels)\n",
    "# Model Performance\n",
    "# Average Error: 3.6561 degrees.\n",
    "# Accuracy = 93.83%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ffabf47-3506-4d4b-b4b1-868d42f1712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of nan%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n",
    "# Improvement of 0.50%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f71ed-6c0d-48df-a088-7b21898a4d22",
   "metadata": {},
   "source": [
    "## Random forest with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "73c2d948-8d50-4da9-b2ef-e1ba3b65885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import graphviz\n",
    "from tqdm import tqdm\n",
    "from random import randrange\n",
    "from sklearn import svm, metrics, tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "038c68ee-ea90-4cef-be00-9c751b686b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Définir le chemin du dossier contenant les images d'entraînement et de test\n",
    "    train_dir = \"./Data/chest_Xray/train/\"\n",
    "    test_dir = \"./Data/chest_Xray/test/\"\n",
    "    val_dir = \"./Data/chest_Xray/val/\"\n",
    "\n",
    "    # Définir le nombre de voisins à utiliser pour la classification K-NN\n",
    "    # n_neighbors = 5\n",
    "\n",
    "    # Charger les images d'entraînement et de test, et leurs étiquettes\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for foldername in tqdm([\"NORMAL\", \"PNEUMONIA\"]): # os.listdir(train_dir)\n",
    "        label = 0 if foldername == \"NORMAL\" else 1\n",
    "        folderpath = os.path.join(train_dir, foldername)\n",
    "        for filename in os.listdir(folderpath):\n",
    "            if filename.endswith(\".jpeg\"):\n",
    "                imgpath = os.path.join(folderpath, filename)\n",
    "                img = cv2.imread(imgpath)\n",
    "                if img is None:\n",
    "                    print('Wrong path:', imgpath)\n",
    "                else:\n",
    "                    img = cv2.resize(img, (64, 64))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    train_images.append(img.flatten())\n",
    "                    train_labels.append(label)\n",
    "\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    for foldername in tqdm([\"NORMAL\", \"PNEUMONIA\"]): # os.listdir(test_dir)\n",
    "        label = 0 if foldername == \"NORMAL\" else 1\n",
    "        folderpath = os.path.join(test_dir, foldername)\n",
    "        for filename in os.listdir(folderpath):\n",
    "            if filename.endswith(\".jpeg\"):\n",
    "                imgpath = os.path.join(folderpath, filename)\n",
    "                img = cv2.imread(imgpath)\n",
    "                if img is None:\n",
    "                    print('Wrong path:', imgpath)\n",
    "                else:\n",
    "                    img = cv2.resize(img, (64, 64))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    test_images.append(img.flatten())\n",
    "                    test_labels.append(label)\n",
    "    \n",
    "    val_images = []\n",
    "    val_labels = []\n",
    "    for foldername in tqdm([\"NORMAL\", \"PNEUMONIA\"]): # os.listdir(test_dir)\n",
    "        label = 0 if foldername == \"NORMAL\" else 1\n",
    "        folderpath = os.path.join(val_dir, foldername)\n",
    "        for filename in os.listdir(folderpath):\n",
    "            if filename.endswith(\".jpeg\"):\n",
    "                imgpath = os.path.join(folderpath, filename)\n",
    "                img = cv2.imread(imgpath)\n",
    "                if img is None:\n",
    "                    print('Wrong path:', imgpath)\n",
    "                else:\n",
    "                    img = cv2.resize(img, (64, 64))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    val_images.append(img.flatten())\n",
    "                    val_labels.append(label)\n",
    "                    \n",
    "    print(\"Finished in\", round((time.time() - start_time), 1), \"s\")\n",
    "                    \n",
    "    return train_images, train_labels, test_images, test_labels, val_images, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f461f7ff-9594-4ed6-a315-f11a3246c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_tree_forest(estimators, max_depth, np_images_training, np_labels_training, np_images_testing, np_labels_testing):\n",
    "        # n_estimators = + le nombre est grand, + les performances seront bonnes mais le code sera ralenti\n",
    "        clf = RandomForestClassifier(n_estimators=estimators, max_depth=max_depth, min_samples_split=2, random_state=0)\n",
    "        clf = clf.fit(np_images_training, np_labels_training)\n",
    "\n",
    "        # scores = cross_val_score(clf, self.np_images_training, self.np_labels_training, cv=5)\n",
    "        # print(scores.mean())\n",
    "\n",
    "        # create graph in a pdf\n",
    "        # take a random tree in the forest and display it !!!\n",
    "        estimator = clf.estimators_[randrange(estimators)]\n",
    "        dot_data = export_graphviz(estimator, out_file=None, filled=True, rounded=True, special_characters=True)\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        graph.render(\"Tree_Forest_Graph\")\n",
    "\n",
    "        # Predict the response for test dataset\n",
    "        predicted = clf.predict(np_images_testing)\n",
    "        print(\"Accuracy:\", metrics.accuracy_score(np_labels_testing, predicted))\n",
    "        print(\"Confusion matrix:\\n\", confusion_matrix(np_labels_testing, predicted))\n",
    "        print(\"Mean squared error:\", mean_squared_error(np_labels_testing, predicted, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5e77240-ffdc-4bc9-ae8e-1a58377f630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:19<00:00, 39.54s/it]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.65s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 88.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, test_images, test_labels, val_images, val_labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e297f870-ab57-461f-9856-2b793e7f7ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Confusion matrix: [[ 83 151]\n",
      " [  5 385]]\n",
      "Mean squared error: 0.5\n"
     ]
    }
   ],
   "source": [
    "random_tree_forest(100, 5, train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "83329d2c-fc17-4a01-8b63-e08c4f260301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7419871794871795\n",
      "Confusion matrix: [[ 77 157]\n",
      " [  4 386]]\n",
      "Mean squared error: 0.5079496239912188\n"
     ]
    }
   ],
   "source": [
    "random_tree_forest(1000, 5, train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b692db7d-03cc-4ab6-ac80-3b86a1b0ddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Estimators: 10\n",
      "Accuracy: 0.7596153846153846\n",
      "Confusion matrix:\n",
      " [[ 90 144]\n",
      " [  6 384]]\n",
      "Mean squared error: 0.4902903378454601\n",
      "\n",
      "====================\n",
      "Estimators: 100\n",
      "Accuracy: 0.75\n",
      "Confusion matrix:\n",
      " [[ 83 151]\n",
      " [  5 385]]\n",
      "Mean squared error: 0.5\n",
      "\n",
      "====================\n",
      "Estimators: 250\n",
      "Accuracy: 0.7483974358974359\n",
      "Confusion matrix:\n",
      " [[ 81 153]\n",
      " [  4 386]]\n",
      "Mean squared error: 0.5016000040894778\n",
      "\n",
      "====================\n",
      "Estimators: 500\n",
      "Accuracy: 0.7451923076923077\n",
      "Confusion matrix:\n",
      " [[ 79 155]\n",
      " [  4 386]]\n",
      "Mean squared error: 0.5047847980156418\n",
      "\n",
      "====================\n",
      "Estimators: 750\n",
      "Accuracy: 0.7419871794871795\n",
      "Confusion matrix:\n",
      " [[ 78 156]\n",
      " [  5 385]]\n",
      "Mean squared error: 0.5079496239912188\n",
      "\n",
      "====================\n",
      "Estimators: 1000\n",
      "Accuracy: 0.7419871794871795\n",
      "Confusion matrix:\n",
      " [[ 77 157]\n",
      " [  4 386]]\n",
      "Mean squared error: 0.5079496239912188\n",
      "\n",
      "====================\n",
      "Estimators: 2000\n",
      "Accuracy: 0.7419871794871795\n",
      "Confusion matrix:\n",
      " [[ 78 156]\n",
      " [  5 385]]\n",
      "Mean squared error: 0.5079496239912188\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 100, 250, 500, 750, 1000, 2000]:\n",
    "    print(\"\\n====================\")\n",
    "    print(\"Estimators:\", i)\n",
    "    random_tree_forest(i, 5, train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb14933-05d6-448f-ac33-7fb2fa175249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rappel precision and rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa6a2d71-f0d7-4519-816e-f656e52f2f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert ZoidbergRandomForest.ipynb to html\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from Tool import tool\n",
    "tool.convert2html(\"ZoidbergRandomForest.ipynb\", \"RandomForestDraft_28-03-23\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
