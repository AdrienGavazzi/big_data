{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6679e558-771d-4e9d-9b72-327a8b0a9249",
   "metadata": {},
   "source": [
    "# Text classification with Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a3508-86bf-42f0-8592-5b6fe1bfe782",
   "metadata": {},
   "source": [
    "https://reintech.io/blog/how-to-create-a-text-classification-model-with-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0325bc0f-d238-470e-9554-8778511e8b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import feature_extraction, pipeline, linear_model, metrics\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from geotext import GeoText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126589e-c49c-4464-afdc-6f24f76d6e34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test NLP ( MoltinomailNB ) News Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d19148e2-e4b3-403c-942c-f7d4c806514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:  18846\n",
      "Number of categories:  20\n"
     ]
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)\n",
    "print(\"Number of documents: \", len(newsgroups.data))\n",
    "print(\"Number of categories: \", len(newsgroups.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c745ab82-c298-4e79-968d-81e813a79218",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', analyzer=stemmed_words)\n",
    "X = vectorizer.fit_transform(newsgroups.data)\n",
    "y = newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b4d09c-3d68-4da3-befb-5cb706c6161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "106e5fce-18ce-4476-8059-c412eaa5bc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4141b49d-e5b6-4886-9830-4d1e7248b6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.32%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59051d1d-6202-48fe-a743-7f0906fada1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 12, 14, ...,  0, 15, 14])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77816980-2c45-4e91-bbdf-3284876913c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## NLP ( MoltinomailNB )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cf4ffaa4-dbb1-4d20-8507-dd8716e13a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Sentences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d1f5e22-84af-407f-9af6-63ecd0599983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('french')\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='french', analyzer=stemmed_words)\n",
    "X = vectorizer.fit_transform(df[\"sentence\"])\n",
    "y = df.iloc[:, 1] + ' to ' + df.iloc[:, 2]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a12783f6-a774-4317-99f0-8aef415e0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.75%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39e18802-d8d4-4f50-985d-b8d92991727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "df_pred = df[-y_pred.size:]\n",
    "df_pred.loc[df_pred.index, \"prediction\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8fdf87c7-a158-41d6-a534-ffb4c2c374f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>departure</th>\n",
       "      <th>arrival</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>Je veux prendre le train de Clermont-Ferrand à...</td>\n",
       "      <td>Clermont-Ferrand</td>\n",
       "      <td>Saint-Denis</td>\n",
       "      <td>Nantes to Saint-Denis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>Le train de Paris à Rouen offre une vue magnif...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Rouen</td>\n",
       "      <td>Limoges to Le Mans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>Je prévois de voyager de Rouen à Marseille en ...</td>\n",
       "      <td>Rouen</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Marseille to Saint-Étienne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Pour mes prochaines vacances, je vais de Bézie...</td>\n",
       "      <td>Béziers</td>\n",
       "      <td>Tourcoing</td>\n",
       "      <td>Le Havre to Le Mans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>Je souhaite découvrir Calais en prenant le tra...</td>\n",
       "      <td>Nîmes</td>\n",
       "      <td>Calais</td>\n",
       "      <td>Tourcoing to Nîmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Je veux prendre le train de Bordeaux à La Roch...</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>La Rochelle</td>\n",
       "      <td>Bordeaux to Limoges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Le train est le meilleur moyen de se rendre de...</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Tourcoing to Nîmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Allons de Pau à Toulon en train, qu'en penses-...</td>\n",
       "      <td>Pau</td>\n",
       "      <td>Toulon</td>\n",
       "      <td>Calais to Tourcoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Je souhaite découvrir Marseille en prenant le ...</td>\n",
       "      <td>Orléans</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Toulon to Lille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Le train de Paris à Rennes est-il disponible d...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>Nice to Le Mans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence         departure  \\\n",
       "1600  Je veux prendre le train de Clermont-Ferrand à...  Clermont-Ferrand   \n",
       "1601  Le train de Paris à Rouen offre une vue magnif...             Paris   \n",
       "1602  Je prévois de voyager de Rouen à Marseille en ...             Rouen   \n",
       "1603  Pour mes prochaines vacances, je vais de Bézie...           Béziers   \n",
       "1604  Je souhaite découvrir Calais en prenant le tra...             Nîmes   \n",
       "...                                                 ...               ...   \n",
       "1995  Je veux prendre le train de Bordeaux à La Roch...          Bordeaux   \n",
       "1996  Le train est le meilleur moyen de se rendre de...              Nice   \n",
       "1997  Allons de Pau à Toulon en train, qu'en penses-...               Pau   \n",
       "1998  Je souhaite découvrir Marseille en prenant le ...           Orléans   \n",
       "1999  Le train de Paris à Rennes est-il disponible d...             Paris   \n",
       "\n",
       "          arrival                  prediction  \n",
       "1600  Saint-Denis       Nantes to Saint-Denis  \n",
       "1601        Rouen          Limoges to Le Mans  \n",
       "1602    Marseille  Marseille to Saint-Étienne  \n",
       "1603    Tourcoing         Le Havre to Le Mans  \n",
       "1604       Calais          Tourcoing to Nîmes  \n",
       "...           ...                         ...  \n",
       "1995  La Rochelle         Bordeaux to Limoges  \n",
       "1996        Lille          Tourcoing to Nîmes  \n",
       "1997       Toulon         Calais to Tourcoing  \n",
       "1998    Marseille             Toulon to Lille  \n",
       "1999       Rennes             Nice to Le Mans  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0d5e-ac99-482a-b5d6-16d7e7dfbbc2",
   "metadata": {},
   "source": [
    "## NLP ( SVC & RandomForest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "20c71409-0e72-4d64-9707-9346519b5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Sentences.csv\")\n",
    "\n",
    "# Create lists to store sentences, departure cities, and arrival cities\n",
    "all_sentences = df[\"sentence\"]\n",
    "all_departure_cities = df[\"departure\"]\n",
    "all_arrival_cities = df[\"arrival\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c88bb2-50a7-45eb-8794-a8f3325b310d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### With detection of cities with geotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4acadbdf-651c-4f28-8fb9-acd081e46914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract cities from a sentence\n",
    "def extract_cities_from_sentence(sentence):\n",
    "    places = GeoText(sentence)\n",
    "    cities = list(places.cities)\n",
    "    if len(cities) >= 2:\n",
    "        return cities[0], cities[1]\n",
    "    elif len(cities) == 1:\n",
    "        return cities[0], None\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Apply the extract_cities_from_sentence function to each row in the DataFrame\n",
    "df[[\"city_1\", \"city_2\"]] = df[\"sentence\"].apply(lambda x: pd.Series(extract_cities_from_sentence(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8a11d12d-8f57-4d6d-9634-8933368c7ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departure city prediction accuracy: 41.50%\n",
      "Arrival city prediction accuracy: 50.75%\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing: Tokenization, lowercasing, and punctuation removal\n",
    "all_sentences = [f\"{sentence}, {city1}, {city2}\" for sentence, city1, city2 in df[[\"sentence\", \"city_1\", \"city_2\"]].values]\n",
    "all_sentences = [sentence.lower().replace(r'[^\\w\\s]', '') for sentence in all_sentences]\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf_vectorizer.fit_transform(all_sentences)\n",
    "\n",
    "# Label encoding for departure and arrival cities\n",
    "y_departure_encoded = all_departure_cities\n",
    "y_arrival_encoded = all_arrival_cities\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_departure_train, y_departure_test = train_test_split(\n",
    "    X, y_departure_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_arrival_train, y_arrival_test = train_test_split(\n",
    "    X, y_arrival_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Support Vector Machine (SVM) classifier for departure cities\n",
    "departure_classifier = SVC(C=0.1, kernel='linear')\n",
    "departure_classifier.fit(X_train, y_departure_train)\n",
    "\n",
    "# Train a Random Forest classifier for arrival cities\n",
    "arrival_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "arrival_classifier.fit(X_train, y_arrival_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_departure_pred = departure_classifier.predict(X_test)\n",
    "y_arrival_pred = arrival_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "departure_accuracy = accuracy_score(y_departure_test, y_departure_pred)\n",
    "arrival_accuracy = accuracy_score(y_arrival_test, y_arrival_pred)\n",
    "\n",
    "# Print the accuracy of the models\n",
    "print(f\"Departure city prediction accuracy: {departure_accuracy * 100:.2f}%\")\n",
    "print(f\"Arrival city prediction accuracy: {arrival_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a18a3-1a99-4508-90ca-a3f99f169ca9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Without detection of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab78fd51-cf8a-4e0e-8afa-01b9bc32af89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departure city prediction accuracy: 50.25%\n",
      "Arrival city prediction accuracy: 45.50%\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing: Tokenization, lowercasing, and punctuation removal\n",
    "all_sentences = [sentence.lower().replace(r'[^\\w\\s]', '') for sentence in all_sentences]\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf_vectorizer.fit_transform(all_sentences)\n",
    "\n",
    "# Label encoding for departure and arrival cities\n",
    "y_departure_encoded = all_departure_cities\n",
    "y_arrival_encoded = all_arrival_cities\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_departure_train, y_departure_test = train_test_split(\n",
    "    X, y_departure_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_arrival_train, y_arrival_test = train_test_split(\n",
    "    X, y_arrival_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Support Vector Machine (SVM) classifier for departure cities\n",
    "departure_classifier = SVC(kernel='linear')\n",
    "departure_classifier.fit(X_train, y_departure_train)\n",
    "\n",
    "# Train a Random Forest classifier for arrival cities\n",
    "arrival_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "arrival_classifier.fit(X_train, y_arrival_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_departure_pred = departure_classifier.predict(X_test)\n",
    "y_arrival_pred = arrival_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "departure_accuracy = accuracy_score(y_departure_test, y_departure_pred)\n",
    "arrival_accuracy = accuracy_score(y_arrival_test, y_arrival_pred)\n",
    "\n",
    "# Print the accuracy of the models\n",
    "print(f\"Departure city prediction accuracy: {departure_accuracy * 100:.2f}%\")\n",
    "print(f\"Arrival city prediction accuracy: {arrival_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19cb65f5-43df-4be2-833a-5da48f2855f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>departure</th>\n",
       "      <th>arrival</th>\n",
       "      <th>prediction_departure</th>\n",
       "      <th>prediction_arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>Je veux prendre le train de Clermont-Ferrand à...</td>\n",
       "      <td>Clermont-Ferrand</td>\n",
       "      <td>Saint-Denis</td>\n",
       "      <td>Saint-Denis</td>\n",
       "      <td>Saint-Denis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>Le train de Paris à Rouen offre une vue magnif...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Rouen</td>\n",
       "      <td>Béziers</td>\n",
       "      <td>Le Mans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>Je prévois de voyager de Rouen à Marseille en ...</td>\n",
       "      <td>Rouen</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Saint-Étienne</td>\n",
       "      <td>Saint-Étienne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Pour mes prochaines vacances, je vais de Bézie...</td>\n",
       "      <td>Béziers</td>\n",
       "      <td>Tourcoing</td>\n",
       "      <td>Le Mans</td>\n",
       "      <td>Rouen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>Je souhaite découvrir Calais en prenant le tra...</td>\n",
       "      <td>Nîmes</td>\n",
       "      <td>Calais</td>\n",
       "      <td>Nîmes</td>\n",
       "      <td>Lille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Je veux prendre le train de Bordeaux à La Roch...</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>La Rochelle</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Limoges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Le train est le meilleur moyen de se rendre de...</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Nîmes</td>\n",
       "      <td>Nîmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Allons de Pau à Toulon en train, qu'en penses-...</td>\n",
       "      <td>Pau</td>\n",
       "      <td>Toulon</td>\n",
       "      <td>Toulon</td>\n",
       "      <td>Calais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Je souhaite découvrir Marseille en prenant le ...</td>\n",
       "      <td>Orléans</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Toulon</td>\n",
       "      <td>Béziers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Le train de Paris à Rennes est-il disponible d...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Le Havre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence         departure  \\\n",
       "1600  Je veux prendre le train de Clermont-Ferrand à...  Clermont-Ferrand   \n",
       "1601  Le train de Paris à Rouen offre une vue magnif...             Paris   \n",
       "1602  Je prévois de voyager de Rouen à Marseille en ...             Rouen   \n",
       "1603  Pour mes prochaines vacances, je vais de Bézie...           Béziers   \n",
       "1604  Je souhaite découvrir Calais en prenant le tra...             Nîmes   \n",
       "...                                                 ...               ...   \n",
       "1995  Je veux prendre le train de Bordeaux à La Roch...          Bordeaux   \n",
       "1996  Le train est le meilleur moyen de se rendre de...              Nice   \n",
       "1997  Allons de Pau à Toulon en train, qu'en penses-...               Pau   \n",
       "1998  Je souhaite découvrir Marseille en prenant le ...           Orléans   \n",
       "1999  Le train de Paris à Rennes est-il disponible d...             Paris   \n",
       "\n",
       "          arrival prediction_departure prediction_arrival  \n",
       "1600  Saint-Denis          Saint-Denis        Saint-Denis  \n",
       "1601        Rouen              Béziers            Le Mans  \n",
       "1602    Marseille        Saint-Étienne      Saint-Étienne  \n",
       "1603    Tourcoing              Le Mans              Rouen  \n",
       "1604       Calais                Nîmes              Lille  \n",
       "...           ...                  ...                ...  \n",
       "1995  La Rochelle             Bordeaux            Limoges  \n",
       "1996        Lille                Nîmes              Nîmes  \n",
       "1997       Toulon               Toulon             Calais  \n",
       "1998    Marseille               Toulon            Béziers  \n",
       "1999       Rennes                 Nice           Le Havre  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = df[-y_departure_pred.size:]\n",
    "df_pred.loc[df_pred.index, \"prediction_departure\"] = y_departure_pred\n",
    "df_pred.loc[df_pred.index, \"prediction_arrival\"] = y_arrival_pred\n",
    "\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a49f900f-0882-487c-8453-0b00cee7cce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departure city prediction accuracy: 52.25%\n",
      "Arrival city prediction accuracy: 44.25%\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"Sentences.csv\")\n",
    "\n",
    "# Separate the data into input sentences and departure/arrival cities\n",
    "all_sentences = df[\"sentence\"]\n",
    "all_departure_cities = df[\"departure\"]\n",
    "all_arrival_cities = df[\"arrival\"]\n",
    "\n",
    "# Data preprocessing: Tokenization, lowercasing, and punctuation removal\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "all_sentences = [preprocess_text(sentence) for sentence in all_sentences]\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf_vectorizer.fit_transform(all_sentences)\n",
    "\n",
    "# Label encoding for departure and arrival cities\n",
    "y_departure_encoded = all_departure_cities\n",
    "y_arrival_encoded = all_arrival_cities\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_departure_train, y_departure_test = train_test_split(\n",
    "    X, y_departure_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_arrival_train, y_arrival_test = train_test_split(\n",
    "    X, y_arrival_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Support Vector Machine (SVM) classifier for departure cities\n",
    "departure_classifier = SVC(C=0.1, kernel='linear')\n",
    "departure_classifier.fit(X_train, y_departure_train)\n",
    "\n",
    "# Train a Random Forest classifier for arrival cities\n",
    "arrival_classifier = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "arrival_classifier.fit(X_train, y_arrival_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_departure_pred = departure_classifier.predict(X_test)\n",
    "y_arrival_pred = arrival_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "departure_accuracy = accuracy_score(y_departure_test, y_departure_pred)\n",
    "arrival_accuracy = accuracy_score(y_arrival_test, y_arrival_pred)\n",
    "\n",
    "# Print the accuracy of the models\n",
    "print(f\"Departure city prediction accuracy: {departure_accuracy * 100:.2f}%\")\n",
    "print(f\"Arrival city prediction accuracy: {arrival_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "113bccc8-72de-4d29-a481-16c7672b4a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>departure</th>\n",
       "      <th>arrival</th>\n",
       "      <th>prediction_departure</th>\n",
       "      <th>prediction_arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>Je veux prendre le train de Clermont-Ferrand à...</td>\n",
       "      <td>Clermont-Ferrand</td>\n",
       "      <td>Saint-Denis</td>\n",
       "      <td>Saint-Denis</td>\n",
       "      <td>Saint-Denis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>Le train de Paris à Rouen offre une vue magnif...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Rouen</td>\n",
       "      <td>Béziers</td>\n",
       "      <td>Le Mans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>Je prévois de voyager de Rouen à Marseille en ...</td>\n",
       "      <td>Rouen</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Saint-Étienne</td>\n",
       "      <td>Lyon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Pour mes prochaines vacances, je vais de Bézie...</td>\n",
       "      <td>Béziers</td>\n",
       "      <td>Tourcoing</td>\n",
       "      <td>Le Mans</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>Je souhaite découvrir Calais en prenant le tra...</td>\n",
       "      <td>Nîmes</td>\n",
       "      <td>Calais</td>\n",
       "      <td>Nîmes</td>\n",
       "      <td>Lille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Je veux prendre le train de Bordeaux à La Roch...</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>La Rochelle</td>\n",
       "      <td>Limoges</td>\n",
       "      <td>Limoges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Le train est le meilleur moyen de se rendre de...</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Nîmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Allons de Pau à Toulon en train, qu'en penses-...</td>\n",
       "      <td>Pau</td>\n",
       "      <td>Toulon</td>\n",
       "      <td>Calais</td>\n",
       "      <td>Calais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Je souhaite découvrir Marseille en prenant le ...</td>\n",
       "      <td>Orléans</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Toulon</td>\n",
       "      <td>Béziers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Le train de Paris à Rennes est-il disponible d...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Rennes</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence         departure  \\\n",
       "1600  Je veux prendre le train de Clermont-Ferrand à...  Clermont-Ferrand   \n",
       "1601  Le train de Paris à Rouen offre une vue magnif...             Paris   \n",
       "1602  Je prévois de voyager de Rouen à Marseille en ...             Rouen   \n",
       "1603  Pour mes prochaines vacances, je vais de Bézie...           Béziers   \n",
       "1604  Je souhaite découvrir Calais en prenant le tra...             Nîmes   \n",
       "...                                                 ...               ...   \n",
       "1995  Je veux prendre le train de Bordeaux à La Roch...          Bordeaux   \n",
       "1996  Le train est le meilleur moyen de se rendre de...              Nice   \n",
       "1997  Allons de Pau à Toulon en train, qu'en penses-...               Pau   \n",
       "1998  Je souhaite découvrir Marseille en prenant le ...           Orléans   \n",
       "1999  Le train de Paris à Rennes est-il disponible d...             Paris   \n",
       "\n",
       "          arrival prediction_departure prediction_arrival  \n",
       "1600  Saint-Denis          Saint-Denis        Saint-Denis  \n",
       "1601        Rouen              Béziers            Le Mans  \n",
       "1602    Marseille        Saint-Étienne               Lyon  \n",
       "1603    Tourcoing              Le Mans              Paris  \n",
       "1604       Calais                Nîmes              Lille  \n",
       "...           ...                  ...                ...  \n",
       "1995  La Rochelle              Limoges            Limoges  \n",
       "1996        Lille                Paris              Nîmes  \n",
       "1997       Toulon               Calais             Calais  \n",
       "1998    Marseille               Toulon            Béziers  \n",
       "1999       Rennes                 Nice               Nice  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = df[-y_departure_pred.size:]\n",
    "df_pred.loc[df_pred.index, \"prediction_departure\"] = y_departure_pred\n",
    "df_pred.loc[df_pred.index, \"prediction_arrival\"] = y_arrival_pred\n",
    "\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d664d4-1231-497d-bc41-a737ebe98946",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Find HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "22848253-0b0d-4c43-9c65-65c38e6a6cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM hyperparameters: SVC(C=0.1, kernel='linear')\n",
      "Best Random Forest hyperparameters: RandomForestClassifier(max_depth=10, random_state=42)\n",
      "Departure city prediction accuracy: 52.25%\n",
      "Arrival city prediction accuracy: 51.50%\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"Sentences.csv\")\n",
    "\n",
    "# Separate the data into input sentences and departure/arrival cities\n",
    "all_sentences = df[\"sentence\"]\n",
    "all_departure_cities = df[\"departure\"]\n",
    "all_arrival_cities = df[\"arrival\"]\n",
    "\n",
    "# Data preprocessing: Tokenization, lowercasing, and punctuation removal\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "all_sentences = [preprocess_text(sentence) for sentence in all_sentences]\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf_vectorizer.fit_transform(all_sentences)\n",
    "\n",
    "# Label encoding for departure and arrival cities\n",
    "y_departure_encoded = all_departure_cities\n",
    "y_arrival_encoded = all_arrival_cities\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_departure_train, y_departure_test = train_test_split(\n",
    "    X, y_departure_encoded, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_arrival_train, y_arrival_test = train_test_split(\n",
    "    X, y_arrival_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for Support Vector Machine (SVM)\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "}\n",
    "\n",
    "svm_grid_search = GridSearchCV(SVC(), param_grid_svm, cv=5, n_jobs=-1)\n",
    "svm_grid_search.fit(X_train, y_departure_train)\n",
    "\n",
    "best_svm = svm_grid_search.best_estimator_\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_arrival_train)\n",
    "\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_departure_pred = best_svm.predict(X_test)\n",
    "y_arrival_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "departure_accuracy = accuracy_score(y_departure_test, y_departure_pred)\n",
    "arrival_accuracy = accuracy_score(y_arrival_test, y_arrival_pred)\n",
    "\n",
    "# Print the best hyperparameters and accuracy\n",
    "print(\"Best SVM hyperparameters:\", best_svm)\n",
    "print(\"Best Random Forest hyperparameters:\", best_rf)\n",
    "print(f\"Departure city prediction accuracy: {departure_accuracy * 100:.2f}%\")\n",
    "print(f\"Arrival city prediction accuracy: {arrival_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57411481-a7ec-45d1-a671-a130eb26f428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
